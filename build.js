/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./dist/lexer.js":
/*!***********************!*\
  !*** ./dist/lexer.js ***!
  \***********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.lexer = void 0;\nconst moo_1 = __importDefault(__webpack_require__(/*! moo */ \"./node_modules/moo/moo.js\"));\nexports.lexer = moo_1.default.compile({\n    ws: /[ \\t]+/,\n    nl: { match: /[\\n\\s]/, lineBreaks: true },\n    comment: {\n        match: /\\/\\/[^\\n]*/,\n        value: s => s.substring(1)\n    },\n    string_literal: {\n        match: /\"(?:[^\\n\\\\\"]|\\\\[\"\\\\ntbfr])*\"/,\n        value: s => JSON.parse(s)\n    },\n    number_literal: {\n        match: /[0-9]+(?:\\.[0-9]+)?/,\n        value: s => Number(s)\n    },\n    intrinsic: {\n        match: /\\+|\\-|\\*|divmod|max|print|over|swap|dup|mod|drop|!8|@8|shl|shr|or|and|\\=|\\>|\\</,\n        type: moo_1.default.keywords({\n            plus: \"+\",\n            minus: \"-\",\n            times: \"*\",\n            divmod: \"divmod\",\n            max: \"max\",\n            mod: \"mod\",\n            print: \"print\",\n            eq: \"=\",\n            gt: \">\",\n            lt: \"<\",\n            over: \"over\",\n            swap: \"swap\",\n            dup: \"dup\",\n            drop: \"drop\",\n            store8: \"!8\",\n            load8: \"@8\",\n            shl: \"shl\",\n            shr: \"shr\",\n            or: \"or\",\n            and: \"and\"\n        })\n    },\n    identifier: {\n        match: /[^\\s \\t]+/,\n        type: moo_1.default.keywords({\n            ifStatement: \"if\",\n            elseStatement: \"else\",\n            whileStatement: \"while\",\n            doStatement: \"do\",\n            include: \"include\",\n            memory: \"memory\",\n            proc: \"proc\",\n            constStatement: \"const\",\n            end: \"end\",\n            offset: 'offset',\n            reset: \"reset\",\n            assert: \"assert\",\n            in: \"in\",\n        })\n    },\n});\nexports[\"default\"] = exports.lexer;\n\n\n//# sourceURL=webpack://js-porth/./dist/lexer.js?");

/***/ }),

/***/ "./grammar.js":
/*!********************!*\
  !*** ./grammar.js ***!
  \********************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Generated automatically by nearley, version 2.20.1\n// http://github.com/Hardmath123/nearley\n(function () {\nfunction id(x) { return x[0]; }\n\n    const { lexer } = __webpack_require__(/*! ./dist/lexer */ \"./dist/lexer.js\")\n\nfunction tokenStart(token) {\n    return {\n        line: token.line,\n        col: token.col - 1\n    };\n}\n\nfunction tokenEnd(token) {\n    const lastNewLine = token.text.lastIndexOf(\"\\n\");\n    if (lastNewLine !== -1) {\n        throw new Error(\"Unsupported case: token with line breaks\");\n    }\n    return {\n        line: token.line,\n        col: token.col + token.text.length - 1\n    };\n}\n\nfunction convertToken(token) {\n    return {\n        type: token.type,\n        value: token.value,\n        start: tokenStart(token),\n        end: tokenEnd(token)\n    };\n}\n\nfunction convertTokenId(data) {\n    return convertToken(data[0]);\n}\n\nvar grammar = {\n    Lexer: lexer,\n    ParserRules: [\n    {\"name\": \"program\", \"symbols\": [\"__ml\", \"statements\", \"__ml\"], \"postprocess\": d=>d[1]},\n    {\"name\": \"statements\", \"symbols\": [\"statement\", \"_ml\", \"statements\"], \"postprocess\": (d)=>[d[0], ...d[2]]},\n    {\"name\": \"statements\", \"symbols\": [\"statement\"], \"postprocess\": (d)=>d},\n    {\"name\": \"statement\", \"symbols\": [\"number\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"intrinsic\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"identifier\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"macro\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"proc\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"memory\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"constStatement\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"include\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"conditional\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"whileStatement\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"string_literal\"], \"postprocess\": id},\n    {\"name\": \"statement\", \"symbols\": [\"line_comment\"], \"postprocess\": id},\n    {\"name\": \"whileStatement\", \"symbols\": [(lexer.has(\"whileStatement\") ? {type: \"whileStatement\"} : whileStatement), \"_ml\", \"statements\", \"_ml\", (lexer.has(\"doStatement\") ? {type: \"doStatement\"} : doStatement), \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n           type:\"while\",\n           condition: d[2],\n           body: d[6],\n        })},\n    {\"name\": \"conditional\", \"symbols\": [\"ifStatement\"], \"postprocess\": id},\n    {\"name\": \"conditional\", \"symbols\": [\"ifElse\"], \"postprocess\": id},\n    {\"name\": \"ifElse\", \"symbols\": [(lexer.has(\"ifStatement\") ? {type: \"ifStatement\"} : ifStatement), \"_ml\", \"statements\", \"_ml\", (lexer.has(\"elseStatement\") ? {type: \"elseStatement\"} : elseStatement), \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n            type:\"ifElse\",\n            // condition:d[0],\n            body:d[2],\n            elseBranch:d[6]\n        })},\n    {\"name\": \"ifElse\", \"symbols\": [(lexer.has(\"ifStatement\") ? {type: \"ifStatement\"} : ifStatement), \"_ml\", \"statements\", \"_ml\", (lexer.has(\"elseStatement\") ? {type: \"elseStatement\"} : elseStatement), \"_ml\", \"statements\", \"_ml\", \"conditional\"], \"postprocess\": d=>({\n            type:\"ifElse\",\n            elseCondition: d[6],\n            body:d[2],\n            elseBranch:[d[8]]\n        })},\n    {\"name\": \"ifStatement\", \"symbols\": [(lexer.has(\"ifStatement\") ? {type: \"ifStatement\"} : ifStatement), \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n            type:\"if\",\n           // condition: d[0],\n            body: d[2],\n        })},\n    {\"name\": \"macro\", \"symbols\": [(lexer.has(\"macro\") ? {type: \"macro\"} : macro), \"_ml\", \"identifier\", \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n            type:\"macro\",\n            name:d[2].value,\n            body:d[4]\n        })},\n    {\"name\": \"memory\", \"symbols\": [(lexer.has(\"memory\") ? {type: \"memory\"} : memory), \"_ml\", \"identifier\", \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n            type:\"memory\",\n            name:d[2].value,\n            body:d[4]\n        })},\n    {\"name\": \"proc\", \"symbols\": [(lexer.has(\"proc\") ? {type: \"proc\"} : proc), \"_ml\", \"identifier\", \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n            type:\"proc\",\n            name:d[2].value,\n            body:d[4]\n        })},\n    {\"name\": \"constStatement\", \"symbols\": [(lexer.has(\"constStatement\") ? {type: \"constStatement\"} : constStatement), \"_ml\", \"identifier\", \"_ml\", \"statements\", \"_ml\", (lexer.has(\"end\") ? {type: \"end\"} : end)], \"postprocess\": d=>({\n            type:\"const\",\n            name:d[2].value,\n            body:d[4]\n        })},\n    {\"name\": \"include\", \"symbols\": [(lexer.has(\"include\") ? {type: \"include\"} : include), \"_ml\", \"string_literal\"], \"postprocess\": d=>({\n            type:\"include\",\n            file:d[2],\n        })},\n    {\"name\": \"line_comment\", \"symbols\": [(lexer.has(\"comment\") ? {type: \"comment\"} : comment)], \"postprocess\": convertTokenId},\n    {\"name\": \"string_literal\", \"symbols\": [(lexer.has(\"string_literal\") ? {type: \"string_literal\"} : string_literal)], \"postprocess\": convertTokenId},\n    {\"name\": \"number\", \"symbols\": [(lexer.has(\"number_literal\") ? {type: \"number_literal\"} : number_literal)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"plus\") ? {type: \"plus\"} : plus)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"print\") ? {type: \"print\"} : print)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"minus\") ? {type: \"minus\"} : minus)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"timed\") ? {type: \"timed\"} : timed)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"divmod\") ? {type: \"divmod\"} : divmod)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"mod\") ? {type: \"mod\"} : mod)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"max\") ? {type: \"max\"} : max)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"eq\") ? {type: \"eq\"} : eq)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"gt\") ? {type: \"gt\"} : gt)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"lt\") ? {type: \"lt\"} : lt)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"over\") ? {type: \"over\"} : over)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"swap\") ? {type: \"swap\"} : swap)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"dup\") ? {type: \"dup\"} : dup)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"drop\") ? {type: \"drop\"} : drop)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"store8\") ? {type: \"store8\"} : store8)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"load8\") ? {type: \"load8\"} : load8)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"shl\") ? {type: \"shl\"} : shl)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"shr\") ? {type: \"shr\"} : shr)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"or\") ? {type: \"or\"} : or)], \"postprocess\": convertTokenId},\n    {\"name\": \"intrinsic\", \"symbols\": [(lexer.has(\"and\") ? {type: \"and\"} : and)], \"postprocess\": convertTokenId},\n    {\"name\": \"identifier\", \"symbols\": [(lexer.has(\"identifier\") ? {type: \"identifier\"} : identifier)], \"postprocess\": convertTokenId},\n    {\"name\": \"__ml$ebnf$1\", \"symbols\": []},\n    {\"name\": \"__ml$ebnf$1\", \"symbols\": [\"__ml$ebnf$1\", \"multi_line_ws_char\"], \"postprocess\": function arrpush(d) {return d[0].concat([d[1]]);}},\n    {\"name\": \"__ml\", \"symbols\": [\"__ml$ebnf$1\"]},\n    {\"name\": \"_ml$ebnf$1\", \"symbols\": [\"multi_line_ws_char\"]},\n    {\"name\": \"_ml$ebnf$1\", \"symbols\": [\"_ml$ebnf$1\", \"multi_line_ws_char\"], \"postprocess\": function arrpush(d) {return d[0].concat([d[1]]);}},\n    {\"name\": \"_ml\", \"symbols\": [\"_ml$ebnf$1\"]},\n    {\"name\": \"multi_line_ws_char\", \"symbols\": [(lexer.has(\"ws\") ? {type: \"ws\"} : ws)]},\n    {\"name\": \"multi_line_ws_char\", \"symbols\": [{\"literal\":\"\\n\"}]},\n    {\"name\": \"multi_line_ws_char\", \"symbols\": [{\"literal\":\"\\t\"}]},\n    {\"name\": \"__$ebnf$1\", \"symbols\": [(lexer.has(\"ws\") ? {type: \"ws\"} : ws)]},\n    {\"name\": \"__$ebnf$1\", \"symbols\": [\"__$ebnf$1\", (lexer.has(\"ws\") ? {type: \"ws\"} : ws)], \"postprocess\": function arrpush(d) {return d[0].concat([d[1]]);}},\n    {\"name\": \"__\", \"symbols\": [\"__$ebnf$1\"]},\n    {\"name\": \"_$ebnf$1\", \"symbols\": []},\n    {\"name\": \"_$ebnf$1\", \"symbols\": [\"_$ebnf$1\", (lexer.has(\"ws\") ? {type: \"ws\"} : ws)], \"postprocess\": function arrpush(d) {return d[0].concat([d[1]]);}},\n    {\"name\": \"_\", \"symbols\": [\"_$ebnf$1\"]}\n]\n  , ParserStart: \"program\"\n}\nif ( true&& typeof module.exports !== 'undefined') {\n   module.exports = grammar;\n} else {\n   window.grammar = grammar;\n}\n})();\n\n\n//# sourceURL=webpack://js-porth/./grammar.js?");

/***/ }),

/***/ "./node_modules/moo/moo.js":
/*!*********************************!*\
  !*** ./node_modules/moo/moo.js ***!
  \*********************************/
/***/ (function(module, exports) {

eval("var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;(function(root, factory) {\n  if (true) {\n    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (factory),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?\n\t\t(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__)) /* global define */\n  } else {}\n}(this, function() {\n  'use strict';\n\n  var hasOwnProperty = Object.prototype.hasOwnProperty\n  var toString = Object.prototype.toString\n  var hasSticky = typeof new RegExp().sticky === 'boolean'\n\n  /***************************************************************************/\n\n  function isRegExp(o) { return o && toString.call(o) === '[object RegExp]' }\n  function isObject(o) { return o && typeof o === 'object' && !isRegExp(o) && !Array.isArray(o) }\n\n  function reEscape(s) {\n    return s.replace(/[-\\/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&')\n  }\n  function reGroups(s) {\n    var re = new RegExp('|' + s)\n    return re.exec('').length - 1\n  }\n  function reCapture(s) {\n    return '(' + s + ')'\n  }\n  function reUnion(regexps) {\n    if (!regexps.length) return '(?!)'\n    var source =  regexps.map(function(s) {\n      return \"(?:\" + s + \")\"\n    }).join('|')\n    return \"(?:\" + source + \")\"\n  }\n\n  function regexpOrLiteral(obj) {\n    if (typeof obj === 'string') {\n      return '(?:' + reEscape(obj) + ')'\n\n    } else if (isRegExp(obj)) {\n      // TODO: consider /u support\n      if (obj.ignoreCase) throw new Error('RegExp /i flag not allowed')\n      if (obj.global) throw new Error('RegExp /g flag is implied')\n      if (obj.sticky) throw new Error('RegExp /y flag is implied')\n      if (obj.multiline) throw new Error('RegExp /m flag is implied')\n      return obj.source\n\n    } else {\n      throw new Error('Not a pattern: ' + obj)\n    }\n  }\n\n  function objectToRules(object) {\n    var keys = Object.getOwnPropertyNames(object)\n    var result = []\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      var thing = object[key]\n      var rules = [].concat(thing)\n      if (key === 'include') {\n        for (var j = 0; j < rules.length; j++) {\n          result.push({include: rules[j]})\n        }\n        continue\n      }\n      var match = []\n      rules.forEach(function(rule) {\n        if (isObject(rule)) {\n          if (match.length) result.push(ruleOptions(key, match))\n          result.push(ruleOptions(key, rule))\n          match = []\n        } else {\n          match.push(rule)\n        }\n      })\n      if (match.length) result.push(ruleOptions(key, match))\n    }\n    return result\n  }\n\n  function arrayToRules(array) {\n    var result = []\n    for (var i = 0; i < array.length; i++) {\n      var obj = array[i]\n      if (obj.include) {\n        var include = [].concat(obj.include)\n        for (var j = 0; j < include.length; j++) {\n          result.push({include: include[j]})\n        }\n        continue\n      }\n      if (!obj.type) {\n        throw new Error('Rule has no type: ' + JSON.stringify(obj))\n      }\n      result.push(ruleOptions(obj.type, obj))\n    }\n    return result\n  }\n\n  function ruleOptions(type, obj) {\n    if (!isObject(obj)) {\n      obj = { match: obj }\n    }\n    if (obj.include) {\n      throw new Error('Matching rules cannot also include states')\n    }\n\n    // nb. error and fallback imply lineBreaks\n    var options = {\n      defaultType: type,\n      lineBreaks: !!obj.error || !!obj.fallback,\n      pop: false,\n      next: null,\n      push: null,\n      error: false,\n      fallback: false,\n      value: null,\n      type: null,\n      shouldThrow: false,\n    }\n\n    // Avoid Object.assign(), so we support IE9+\n    for (var key in obj) {\n      if (hasOwnProperty.call(obj, key)) {\n        options[key] = obj[key]\n      }\n    }\n\n    // type transform cannot be a string\n    if (typeof options.type === 'string' && type !== options.type) {\n      throw new Error(\"Type transform cannot be a string (type '\" + options.type + \"' for token '\" + type + \"')\")\n    }\n\n    // convert to array\n    var match = options.match\n    options.match = Array.isArray(match) ? match : match ? [match] : []\n    options.match.sort(function(a, b) {\n      return isRegExp(a) && isRegExp(b) ? 0\n           : isRegExp(b) ? -1 : isRegExp(a) ? +1 : b.length - a.length\n    })\n    return options\n  }\n\n  function toRules(spec) {\n    return Array.isArray(spec) ? arrayToRules(spec) : objectToRules(spec)\n  }\n\n  var defaultErrorRule = ruleOptions('error', {lineBreaks: true, shouldThrow: true})\n  function compileRules(rules, hasStates) {\n    var errorRule = null\n    var fast = Object.create(null)\n    var fastAllowed = true\n    var unicodeFlag = null\n    var groups = []\n    var parts = []\n\n    // If there is a fallback rule, then disable fast matching\n    for (var i = 0; i < rules.length; i++) {\n      if (rules[i].fallback) {\n        fastAllowed = false\n      }\n    }\n\n    for (var i = 0; i < rules.length; i++) {\n      var options = rules[i]\n\n      if (options.include) {\n        // all valid inclusions are removed by states() preprocessor\n        throw new Error('Inheritance is not allowed in stateless lexers')\n      }\n\n      if (options.error || options.fallback) {\n        // errorRule can only be set once\n        if (errorRule) {\n          if (!options.fallback === !errorRule.fallback) {\n            throw new Error(\"Multiple \" + (options.fallback ? \"fallback\" : \"error\") + \" rules not allowed (for token '\" + options.defaultType + \"')\")\n          } else {\n            throw new Error(\"fallback and error are mutually exclusive (for token '\" + options.defaultType + \"')\")\n          }\n        }\n        errorRule = options\n      }\n\n      var match = options.match.slice()\n      if (fastAllowed) {\n        while (match.length && typeof match[0] === 'string' && match[0].length === 1) {\n          var word = match.shift()\n          fast[word.charCodeAt(0)] = options\n        }\n      }\n\n      // Warn about inappropriate state-switching options\n      if (options.pop || options.push || options.next) {\n        if (!hasStates) {\n          throw new Error(\"State-switching options are not allowed in stateless lexers (for token '\" + options.defaultType + \"')\")\n        }\n        if (options.fallback) {\n          throw new Error(\"State-switching options are not allowed on fallback tokens (for token '\" + options.defaultType + \"')\")\n        }\n      }\n\n      // Only rules with a .match are included in the RegExp\n      if (match.length === 0) {\n        continue\n      }\n      fastAllowed = false\n\n      groups.push(options)\n\n      // Check unicode flag is used everywhere or nowhere\n      for (var j = 0; j < match.length; j++) {\n        var obj = match[j]\n        if (!isRegExp(obj)) {\n          continue\n        }\n\n        if (unicodeFlag === null) {\n          unicodeFlag = obj.unicode\n        } else if (unicodeFlag !== obj.unicode && options.fallback === false) {\n          throw new Error('If one rule is /u then all must be')\n        }\n      }\n\n      // convert to RegExp\n      var pat = reUnion(match.map(regexpOrLiteral))\n\n      // validate\n      var regexp = new RegExp(pat)\n      if (regexp.test(\"\")) {\n        throw new Error(\"RegExp matches empty string: \" + regexp)\n      }\n      var groupCount = reGroups(pat)\n      if (groupCount > 0) {\n        throw new Error(\"RegExp has capture groups: \" + regexp + \"\\nUse (?: … ) instead\")\n      }\n\n      // try and detect rules matching newlines\n      if (!options.lineBreaks && regexp.test('\\n')) {\n        throw new Error('Rule should declare lineBreaks: ' + regexp)\n      }\n\n      // store regex\n      parts.push(reCapture(pat))\n    }\n\n\n    // If there's no fallback rule, use the sticky flag so we only look for\n    // matches at the current index.\n    //\n    // If we don't support the sticky flag, then fake it using an irrefutable\n    // match (i.e. an empty pattern).\n    var fallbackRule = errorRule && errorRule.fallback\n    var flags = hasSticky && !fallbackRule ? 'ym' : 'gm'\n    var suffix = hasSticky || fallbackRule ? '' : '|'\n\n    if (unicodeFlag === true) flags += \"u\"\n    var combined = new RegExp(reUnion(parts) + suffix, flags)\n    return {regexp: combined, groups: groups, fast: fast, error: errorRule || defaultErrorRule}\n  }\n\n  function compile(rules) {\n    var result = compileRules(toRules(rules))\n    return new Lexer({start: result}, 'start')\n  }\n\n  function checkStateGroup(g, name, map) {\n    var state = g && (g.push || g.next)\n    if (state && !map[state]) {\n      throw new Error(\"Missing state '\" + state + \"' (in token '\" + g.defaultType + \"' of state '\" + name + \"')\")\n    }\n    if (g && g.pop && +g.pop !== 1) {\n      throw new Error(\"pop must be 1 (in token '\" + g.defaultType + \"' of state '\" + name + \"')\")\n    }\n  }\n  function compileStates(states, start) {\n    var all = states.$all ? toRules(states.$all) : []\n    delete states.$all\n\n    var keys = Object.getOwnPropertyNames(states)\n    if (!start) start = keys[0]\n\n    var ruleMap = Object.create(null)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      ruleMap[key] = toRules(states[key]).concat(all)\n    }\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      var rules = ruleMap[key]\n      var included = Object.create(null)\n      for (var j = 0; j < rules.length; j++) {\n        var rule = rules[j]\n        if (!rule.include) continue\n        var splice = [j, 1]\n        if (rule.include !== key && !included[rule.include]) {\n          included[rule.include] = true\n          var newRules = ruleMap[rule.include]\n          if (!newRules) {\n            throw new Error(\"Cannot include nonexistent state '\" + rule.include + \"' (in state '\" + key + \"')\")\n          }\n          for (var k = 0; k < newRules.length; k++) {\n            var newRule = newRules[k]\n            if (rules.indexOf(newRule) !== -1) continue\n            splice.push(newRule)\n          }\n        }\n        rules.splice.apply(rules, splice)\n        j--\n      }\n    }\n\n    var map = Object.create(null)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      map[key] = compileRules(ruleMap[key], true)\n    }\n\n    for (var i = 0; i < keys.length; i++) {\n      var name = keys[i]\n      var state = map[name]\n      var groups = state.groups\n      for (var j = 0; j < groups.length; j++) {\n        checkStateGroup(groups[j], name, map)\n      }\n      var fastKeys = Object.getOwnPropertyNames(state.fast)\n      for (var j = 0; j < fastKeys.length; j++) {\n        checkStateGroup(state.fast[fastKeys[j]], name, map)\n      }\n    }\n\n    return new Lexer(map, start)\n  }\n\n  function keywordTransform(map) {\n    var reverseMap = Object.create(null)\n    var byLength = Object.create(null)\n    var types = Object.getOwnPropertyNames(map)\n    for (var i = 0; i < types.length; i++) {\n      var tokenType = types[i]\n      var item = map[tokenType]\n      var keywordList = Array.isArray(item) ? item : [item]\n      keywordList.forEach(function(keyword) {\n        (byLength[keyword.length] = byLength[keyword.length] || []).push(keyword)\n        if (typeof keyword !== 'string') {\n          throw new Error(\"keyword must be string (in keyword '\" + tokenType + \"')\")\n        }\n        reverseMap[keyword] = tokenType\n      })\n    }\n\n    // fast string lookup\n    // https://jsperf.com/string-lookups\n    function str(x) { return JSON.stringify(x) }\n    var source = ''\n    source += 'switch (value.length) {\\n'\n    for (var length in byLength) {\n      var keywords = byLength[length]\n      source += 'case ' + length + ':\\n'\n      source += 'switch (value) {\\n'\n      keywords.forEach(function(keyword) {\n        var tokenType = reverseMap[keyword]\n        source += 'case ' + str(keyword) + ': return ' + str(tokenType) + '\\n'\n      })\n      source += '}\\n'\n    }\n    source += '}\\n'\n    return Function('value', source) // type\n  }\n\n  /***************************************************************************/\n\n  var Lexer = function(states, state) {\n    this.startState = state\n    this.states = states\n    this.buffer = ''\n    this.stack = []\n    this.reset()\n  }\n\n  Lexer.prototype.reset = function(data, info) {\n    this.buffer = data || ''\n    this.index = 0\n    this.line = info ? info.line : 1\n    this.col = info ? info.col : 1\n    this.queuedToken = info ? info.queuedToken : null\n    this.queuedThrow = info ? info.queuedThrow : null\n    this.setState(info ? info.state : this.startState)\n    this.stack = info && info.stack ? info.stack.slice() : []\n    return this\n  }\n\n  Lexer.prototype.save = function() {\n    return {\n      line: this.line,\n      col: this.col,\n      state: this.state,\n      stack: this.stack.slice(),\n      queuedToken: this.queuedToken,\n      queuedThrow: this.queuedThrow,\n    }\n  }\n\n  Lexer.prototype.setState = function(state) {\n    if (!state || this.state === state) return\n    this.state = state\n    var info = this.states[state]\n    this.groups = info.groups\n    this.error = info.error\n    this.re = info.regexp\n    this.fast = info.fast\n  }\n\n  Lexer.prototype.popState = function() {\n    this.setState(this.stack.pop())\n  }\n\n  Lexer.prototype.pushState = function(state) {\n    this.stack.push(this.state)\n    this.setState(state)\n  }\n\n  var eat = hasSticky ? function(re, buffer) { // assume re is /y\n    return re.exec(buffer)\n  } : function(re, buffer) { // assume re is /g\n    var match = re.exec(buffer)\n    // will always match, since we used the |(?:) trick\n    if (match[0].length === 0) {\n      return null\n    }\n    return match\n  }\n\n  Lexer.prototype._getGroup = function(match) {\n    var groupCount = this.groups.length\n    for (var i = 0; i < groupCount; i++) {\n      if (match[i + 1] !== undefined) {\n        return this.groups[i]\n      }\n    }\n    throw new Error('Cannot find token type for matched text')\n  }\n\n  function tokenToString() {\n    return this.value\n  }\n\n  Lexer.prototype.next = function() {\n    var index = this.index\n\n    // If a fallback token matched, we don't need to re-run the RegExp\n    if (this.queuedGroup) {\n      var token = this._token(this.queuedGroup, this.queuedText, index)\n      this.queuedGroup = null\n      this.queuedText = \"\"\n      return token\n    }\n\n    var buffer = this.buffer\n    if (index === buffer.length) {\n      return // EOF\n    }\n\n    // Fast matching for single characters\n    var group = this.fast[buffer.charCodeAt(index)]\n    if (group) {\n      return this._token(group, buffer.charAt(index), index)\n    }\n\n    // Execute RegExp\n    var re = this.re\n    re.lastIndex = index\n    var match = eat(re, buffer)\n\n    // Error tokens match the remaining buffer\n    var error = this.error\n    if (match == null) {\n      return this._token(error, buffer.slice(index, buffer.length), index)\n    }\n\n    var group = this._getGroup(match)\n    var text = match[0]\n\n    if (error.fallback && match.index !== index) {\n      this.queuedGroup = group\n      this.queuedText = text\n\n      // Fallback tokens contain the unmatched portion of the buffer\n      return this._token(error, buffer.slice(index, match.index), index)\n    }\n\n    return this._token(group, text, index)\n  }\n\n  Lexer.prototype._token = function(group, text, offset) {\n    // count line breaks\n    var lineBreaks = 0\n    if (group.lineBreaks) {\n      var matchNL = /\\n/g\n      var nl = 1\n      if (text === '\\n') {\n        lineBreaks = 1\n      } else {\n        while (matchNL.exec(text)) { lineBreaks++; nl = matchNL.lastIndex }\n      }\n    }\n\n    var token = {\n      type: (typeof group.type === 'function' && group.type(text)) || group.defaultType,\n      value: typeof group.value === 'function' ? group.value(text) : text,\n      text: text,\n      toString: tokenToString,\n      offset: offset,\n      lineBreaks: lineBreaks,\n      line: this.line,\n      col: this.col,\n    }\n    // nb. adding more props to token object will make V8 sad!\n\n    var size = text.length\n    this.index += size\n    this.line += lineBreaks\n    if (lineBreaks !== 0) {\n      this.col = size - nl + 1\n    } else {\n      this.col += size\n    }\n\n    // throw, if no rule with {error: true}\n    if (group.shouldThrow) {\n      throw new Error(this.formatError(token, \"invalid syntax\"))\n    }\n\n    if (group.pop) this.popState()\n    else if (group.push) this.pushState(group.push)\n    else if (group.next) this.setState(group.next)\n\n    return token\n  }\n\n  if (typeof Symbol !== 'undefined' && Symbol.iterator) {\n    var LexerIterator = function(lexer) {\n      this.lexer = lexer\n    }\n\n    LexerIterator.prototype.next = function() {\n      var token = this.lexer.next()\n      return {value: token, done: !token}\n    }\n\n    LexerIterator.prototype[Symbol.iterator] = function() {\n      return this\n    }\n\n    Lexer.prototype[Symbol.iterator] = function() {\n      return new LexerIterator(this)\n    }\n  }\n\n  Lexer.prototype.formatError = function(token, message) {\n    if (token == null) {\n      // An undefined token indicates EOF\n      var text = this.buffer.slice(this.index)\n      var token = {\n        text: text,\n        offset: this.index,\n        lineBreaks: text.indexOf('\\n') === -1 ? 0 : 1,\n        line: this.line,\n        col: this.col,\n      }\n    }\n    var start = Math.max(0, token.offset - token.col + 1)\n    var eol = token.lineBreaks ? token.text.indexOf('\\n') : token.text.length\n    var firstLine = this.buffer.substring(start, token.offset + eol)\n    message += \" at line \" + token.line + \" col \" + token.col + \":\\n\\n\"\n    message += \"  \" + firstLine + \"\\n\"\n    message += \"  \" + Array(token.col).join(\" \") + \"^\"\n    return message\n  }\n\n  Lexer.prototype.clone = function() {\n    return new Lexer(this.states, this.state)\n  }\n\n  Lexer.prototype.has = function(tokenType) {\n    return true\n  }\n\n\n  return {\n    compile: compile,\n    states: compileStates,\n    error: Object.freeze({error: true}),\n    fallback: Object.freeze({fallback: true}),\n    keywords: keywordTransform,\n  }\n\n}));\n\n\n//# sourceURL=webpack://js-porth/./node_modules/moo/moo.js?");

/***/ }),

/***/ "./node_modules/nearley/lib/nearley.js":
/*!*********************************************!*\
  !*** ./node_modules/nearley/lib/nearley.js ***!
  \*********************************************/
/***/ (function(module) {

eval("(function(root, factory) {\n    if ( true && module.exports) {\n        module.exports = factory();\n    } else {\n        root.nearley = factory();\n    }\n}(this, function() {\n\n    function Rule(name, symbols, postprocess) {\n        this.id = ++Rule.highestId;\n        this.name = name;\n        this.symbols = symbols;        // a list of literal | regex class | nonterminal\n        this.postprocess = postprocess;\n        return this;\n    }\n    Rule.highestId = 0;\n\n    Rule.prototype.toString = function(withCursorAt) {\n        var symbolSequence = (typeof withCursorAt === \"undefined\")\n                             ? this.symbols.map(getSymbolShortDisplay).join(' ')\n                             : (   this.symbols.slice(0, withCursorAt).map(getSymbolShortDisplay).join(' ')\n                                 + \" ● \"\n                                 + this.symbols.slice(withCursorAt).map(getSymbolShortDisplay).join(' ')     );\n        return this.name + \" → \" + symbolSequence;\n    }\n\n\n    // a State is a rule at a position from a given starting point in the input stream (reference)\n    function State(rule, dot, reference, wantedBy) {\n        this.rule = rule;\n        this.dot = dot;\n        this.reference = reference;\n        this.data = [];\n        this.wantedBy = wantedBy;\n        this.isComplete = this.dot === rule.symbols.length;\n    }\n\n    State.prototype.toString = function() {\n        return \"{\" + this.rule.toString(this.dot) + \"}, from: \" + (this.reference || 0);\n    };\n\n    State.prototype.nextState = function(child) {\n        var state = new State(this.rule, this.dot + 1, this.reference, this.wantedBy);\n        state.left = this;\n        state.right = child;\n        if (state.isComplete) {\n            state.data = state.build();\n            // Having right set here will prevent the right state and its children\n            // form being garbage collected\n            state.right = undefined;\n        }\n        return state;\n    };\n\n    State.prototype.build = function() {\n        var children = [];\n        var node = this;\n        do {\n            children.push(node.right.data);\n            node = node.left;\n        } while (node.left);\n        children.reverse();\n        return children;\n    };\n\n    State.prototype.finish = function() {\n        if (this.rule.postprocess) {\n            this.data = this.rule.postprocess(this.data, this.reference, Parser.fail);\n        }\n    };\n\n\n    function Column(grammar, index) {\n        this.grammar = grammar;\n        this.index = index;\n        this.states = [];\n        this.wants = {}; // states indexed by the non-terminal they expect\n        this.scannable = []; // list of states that expect a token\n        this.completed = {}; // states that are nullable\n    }\n\n\n    Column.prototype.process = function(nextColumn) {\n        var states = this.states;\n        var wants = this.wants;\n        var completed = this.completed;\n\n        for (var w = 0; w < states.length; w++) { // nb. we push() during iteration\n            var state = states[w];\n\n            if (state.isComplete) {\n                state.finish();\n                if (state.data !== Parser.fail) {\n                    // complete\n                    var wantedBy = state.wantedBy;\n                    for (var i = wantedBy.length; i--; ) { // this line is hot\n                        var left = wantedBy[i];\n                        this.complete(left, state);\n                    }\n\n                    // special-case nullables\n                    if (state.reference === this.index) {\n                        // make sure future predictors of this rule get completed.\n                        var exp = state.rule.name;\n                        (this.completed[exp] = this.completed[exp] || []).push(state);\n                    }\n                }\n\n            } else {\n                // queue scannable states\n                var exp = state.rule.symbols[state.dot];\n                if (typeof exp !== 'string') {\n                    this.scannable.push(state);\n                    continue;\n                }\n\n                // predict\n                if (wants[exp]) {\n                    wants[exp].push(state);\n\n                    if (completed.hasOwnProperty(exp)) {\n                        var nulls = completed[exp];\n                        for (var i = 0; i < nulls.length; i++) {\n                            var right = nulls[i];\n                            this.complete(state, right);\n                        }\n                    }\n                } else {\n                    wants[exp] = [state];\n                    this.predict(exp);\n                }\n            }\n        }\n    }\n\n    Column.prototype.predict = function(exp) {\n        var rules = this.grammar.byName[exp] || [];\n\n        for (var i = 0; i < rules.length; i++) {\n            var r = rules[i];\n            var wantedBy = this.wants[exp];\n            var s = new State(r, 0, this.index, wantedBy);\n            this.states.push(s);\n        }\n    }\n\n    Column.prototype.complete = function(left, right) {\n        var copy = left.nextState(right);\n        this.states.push(copy);\n    }\n\n\n    function Grammar(rules, start) {\n        this.rules = rules;\n        this.start = start || this.rules[0].name;\n        var byName = this.byName = {};\n        this.rules.forEach(function(rule) {\n            if (!byName.hasOwnProperty(rule.name)) {\n                byName[rule.name] = [];\n            }\n            byName[rule.name].push(rule);\n        });\n    }\n\n    // So we can allow passing (rules, start) directly to Parser for backwards compatibility\n    Grammar.fromCompiled = function(rules, start) {\n        var lexer = rules.Lexer;\n        if (rules.ParserStart) {\n          start = rules.ParserStart;\n          rules = rules.ParserRules;\n        }\n        var rules = rules.map(function (r) { return (new Rule(r.name, r.symbols, r.postprocess)); });\n        var g = new Grammar(rules, start);\n        g.lexer = lexer; // nb. storing lexer on Grammar is iffy, but unavoidable\n        return g;\n    }\n\n\n    function StreamLexer() {\n      this.reset(\"\");\n    }\n\n    StreamLexer.prototype.reset = function(data, state) {\n        this.buffer = data;\n        this.index = 0;\n        this.line = state ? state.line : 1;\n        this.lastLineBreak = state ? -state.col : 0;\n    }\n\n    StreamLexer.prototype.next = function() {\n        if (this.index < this.buffer.length) {\n            var ch = this.buffer[this.index++];\n            if (ch === '\\n') {\n              this.line += 1;\n              this.lastLineBreak = this.index;\n            }\n            return {value: ch};\n        }\n    }\n\n    StreamLexer.prototype.save = function() {\n      return {\n        line: this.line,\n        col: this.index - this.lastLineBreak,\n      }\n    }\n\n    StreamLexer.prototype.formatError = function(token, message) {\n        // nb. this gets called after consuming the offending token,\n        // so the culprit is index-1\n        var buffer = this.buffer;\n        if (typeof buffer === 'string') {\n            var lines = buffer\n                .split(\"\\n\")\n                .slice(\n                    Math.max(0, this.line - 5), \n                    this.line\n                );\n\n            var nextLineBreak = buffer.indexOf('\\n', this.index);\n            if (nextLineBreak === -1) nextLineBreak = buffer.length;\n            var col = this.index - this.lastLineBreak;\n            var lastLineDigits = String(this.line).length;\n            message += \" at line \" + this.line + \" col \" + col + \":\\n\\n\";\n            message += lines\n                .map(function(line, i) {\n                    return pad(this.line - lines.length + i + 1, lastLineDigits) + \" \" + line;\n                }, this)\n                .join(\"\\n\");\n            message += \"\\n\" + pad(\"\", lastLineDigits + col) + \"^\\n\";\n            return message;\n        } else {\n            return message + \" at index \" + (this.index - 1);\n        }\n\n        function pad(n, length) {\n            var s = String(n);\n            return Array(length - s.length + 1).join(\" \") + s;\n        }\n    }\n\n    function Parser(rules, start, options) {\n        if (rules instanceof Grammar) {\n            var grammar = rules;\n            var options = start;\n        } else {\n            var grammar = Grammar.fromCompiled(rules, start);\n        }\n        this.grammar = grammar;\n\n        // Read options\n        this.options = {\n            keepHistory: false,\n            lexer: grammar.lexer || new StreamLexer,\n        };\n        for (var key in (options || {})) {\n            this.options[key] = options[key];\n        }\n\n        // Setup lexer\n        this.lexer = this.options.lexer;\n        this.lexerState = undefined;\n\n        // Setup a table\n        var column = new Column(grammar, 0);\n        var table = this.table = [column];\n\n        // I could be expecting anything.\n        column.wants[grammar.start] = [];\n        column.predict(grammar.start);\n        // TODO what if start rule is nullable?\n        column.process();\n        this.current = 0; // token index\n    }\n\n    // create a reserved token for indicating a parse fail\n    Parser.fail = {};\n\n    Parser.prototype.feed = function(chunk) {\n        var lexer = this.lexer;\n        lexer.reset(chunk, this.lexerState);\n\n        var token;\n        while (true) {\n            try {\n                token = lexer.next();\n                if (!token) {\n                    break;\n                }\n            } catch (e) {\n                // Create the next column so that the error reporter\n                // can display the correctly predicted states.\n                var nextColumn = new Column(this.grammar, this.current + 1);\n                this.table.push(nextColumn);\n                var err = new Error(this.reportLexerError(e));\n                err.offset = this.current;\n                err.token = e.token;\n                throw err;\n            }\n            // We add new states to table[current+1]\n            var column = this.table[this.current];\n\n            // GC unused states\n            if (!this.options.keepHistory) {\n                delete this.table[this.current - 1];\n            }\n\n            var n = this.current + 1;\n            var nextColumn = new Column(this.grammar, n);\n            this.table.push(nextColumn);\n\n            // Advance all tokens that expect the symbol\n            var literal = token.text !== undefined ? token.text : token.value;\n            var value = lexer.constructor === StreamLexer ? token.value : token;\n            var scannable = column.scannable;\n            for (var w = scannable.length; w--; ) {\n                var state = scannable[w];\n                var expect = state.rule.symbols[state.dot];\n                // Try to consume the token\n                // either regex or literal\n                if (expect.test ? expect.test(value) :\n                    expect.type ? expect.type === token.type\n                                : expect.literal === literal) {\n                    // Add it\n                    var next = state.nextState({data: value, token: token, isToken: true, reference: n - 1});\n                    nextColumn.states.push(next);\n                }\n            }\n\n            // Next, for each of the rules, we either\n            // (a) complete it, and try to see if the reference row expected that\n            //     rule\n            // (b) predict the next nonterminal it expects by adding that\n            //     nonterminal's start state\n            // To prevent duplication, we also keep track of rules we have already\n            // added\n\n            nextColumn.process();\n\n            // If needed, throw an error:\n            if (nextColumn.states.length === 0) {\n                // No states at all! This is not good.\n                var err = new Error(this.reportError(token));\n                err.offset = this.current;\n                err.token = token;\n                throw err;\n            }\n\n            // maybe save lexer state\n            if (this.options.keepHistory) {\n              column.lexerState = lexer.save()\n            }\n\n            this.current++;\n        }\n        if (column) {\n          this.lexerState = lexer.save()\n        }\n\n        // Incrementally keep track of results\n        this.results = this.finish();\n\n        // Allow chaining, for whatever it's worth\n        return this;\n    };\n\n    Parser.prototype.reportLexerError = function(lexerError) {\n        var tokenDisplay, lexerMessage;\n        // Planning to add a token property to moo's thrown error\n        // even on erroring tokens to be used in error display below\n        var token = lexerError.token;\n        if (token) {\n            tokenDisplay = \"input \" + JSON.stringify(token.text[0]) + \" (lexer error)\";\n            lexerMessage = this.lexer.formatError(token, \"Syntax error\");\n        } else {\n            tokenDisplay = \"input (lexer error)\";\n            lexerMessage = lexerError.message;\n        }\n        return this.reportErrorCommon(lexerMessage, tokenDisplay);\n    };\n\n    Parser.prototype.reportError = function(token) {\n        var tokenDisplay = (token.type ? token.type + \" token: \" : \"\") + JSON.stringify(token.value !== undefined ? token.value : token);\n        var lexerMessage = this.lexer.formatError(token, \"Syntax error\");\n        return this.reportErrorCommon(lexerMessage, tokenDisplay);\n    };\n\n    Parser.prototype.reportErrorCommon = function(lexerMessage, tokenDisplay) {\n        var lines = [];\n        lines.push(lexerMessage);\n        var lastColumnIndex = this.table.length - 2;\n        var lastColumn = this.table[lastColumnIndex];\n        var expectantStates = lastColumn.states\n            .filter(function(state) {\n                var nextSymbol = state.rule.symbols[state.dot];\n                return nextSymbol && typeof nextSymbol !== \"string\";\n            });\n\n        if (expectantStates.length === 0) {\n            lines.push('Unexpected ' + tokenDisplay + '. I did not expect any more input. Here is the state of my parse table:\\n');\n            this.displayStateStack(lastColumn.states, lines);\n        } else {\n            lines.push('Unexpected ' + tokenDisplay + '. Instead, I was expecting to see one of the following:\\n');\n            // Display a \"state stack\" for each expectant state\n            // - which shows you how this state came to be, step by step.\n            // If there is more than one derivation, we only display the first one.\n            var stateStacks = expectantStates\n                .map(function(state) {\n                    return this.buildFirstStateStack(state, []) || [state];\n                }, this);\n            // Display each state that is expecting a terminal symbol next.\n            stateStacks.forEach(function(stateStack) {\n                var state = stateStack[0];\n                var nextSymbol = state.rule.symbols[state.dot];\n                var symbolDisplay = this.getSymbolDisplay(nextSymbol);\n                lines.push('A ' + symbolDisplay + ' based on:');\n                this.displayStateStack(stateStack, lines);\n            }, this);\n        }\n        lines.push(\"\");\n        return lines.join(\"\\n\");\n    }\n    \n    Parser.prototype.displayStateStack = function(stateStack, lines) {\n        var lastDisplay;\n        var sameDisplayCount = 0;\n        for (var j = 0; j < stateStack.length; j++) {\n            var state = stateStack[j];\n            var display = state.rule.toString(state.dot);\n            if (display === lastDisplay) {\n                sameDisplayCount++;\n            } else {\n                if (sameDisplayCount > 0) {\n                    lines.push('    ^ ' + sameDisplayCount + ' more lines identical to this');\n                }\n                sameDisplayCount = 0;\n                lines.push('    ' + display);\n            }\n            lastDisplay = display;\n        }\n    };\n\n    Parser.prototype.getSymbolDisplay = function(symbol) {\n        return getSymbolLongDisplay(symbol);\n    };\n\n    /*\n    Builds a the first state stack. You can think of a state stack as the call stack\n    of the recursive-descent parser which the Nearley parse algorithm simulates.\n    A state stack is represented as an array of state objects. Within a\n    state stack, the first item of the array will be the starting\n    state, with each successive item in the array going further back into history.\n\n    This function needs to be given a starting state and an empty array representing\n    the visited states, and it returns an single state stack.\n\n    */\n    Parser.prototype.buildFirstStateStack = function(state, visited) {\n        if (visited.indexOf(state) !== -1) {\n            // Found cycle, return null\n            // to eliminate this path from the results, because\n            // we don't know how to display it meaningfully\n            return null;\n        }\n        if (state.wantedBy.length === 0) {\n            return [state];\n        }\n        var prevState = state.wantedBy[0];\n        var childVisited = [state].concat(visited);\n        var childResult = this.buildFirstStateStack(prevState, childVisited);\n        if (childResult === null) {\n            return null;\n        }\n        return [state].concat(childResult);\n    };\n\n    Parser.prototype.save = function() {\n        var column = this.table[this.current];\n        column.lexerState = this.lexerState;\n        return column;\n    };\n\n    Parser.prototype.restore = function(column) {\n        var index = column.index;\n        this.current = index;\n        this.table[index] = column;\n        this.table.splice(index + 1);\n        this.lexerState = column.lexerState;\n\n        // Incrementally keep track of results\n        this.results = this.finish();\n    };\n\n    // nb. deprecated: use save/restore instead!\n    Parser.prototype.rewind = function(index) {\n        if (!this.options.keepHistory) {\n            throw new Error('set option `keepHistory` to enable rewinding')\n        }\n        // nb. recall column (table) indicies fall between token indicies.\n        //        col 0   --   token 0   --   col 1\n        this.restore(this.table[index]);\n    };\n\n    Parser.prototype.finish = function() {\n        // Return the possible parsings\n        var considerations = [];\n        var start = this.grammar.start;\n        var column = this.table[this.table.length - 1]\n        column.states.forEach(function (t) {\n            if (t.rule.name === start\n                    && t.dot === t.rule.symbols.length\n                    && t.reference === 0\n                    && t.data !== Parser.fail) {\n                considerations.push(t);\n            }\n        });\n        return considerations.map(function(c) {return c.data; });\n    };\n\n    function getSymbolLongDisplay(symbol) {\n        var type = typeof symbol;\n        if (type === \"string\") {\n            return symbol;\n        } else if (type === \"object\") {\n            if (symbol.literal) {\n                return JSON.stringify(symbol.literal);\n            } else if (symbol instanceof RegExp) {\n                return 'character matching ' + symbol;\n            } else if (symbol.type) {\n                return symbol.type + ' token';\n            } else if (symbol.test) {\n                return 'token matching ' + String(symbol.test);\n            } else {\n                throw new Error('Unknown symbol type: ' + symbol);\n            }\n        }\n    }\n\n    function getSymbolShortDisplay(symbol) {\n        var type = typeof symbol;\n        if (type === \"string\") {\n            return symbol;\n        } else if (type === \"object\") {\n            if (symbol.literal) {\n                return JSON.stringify(symbol.literal);\n            } else if (symbol instanceof RegExp) {\n                return symbol.toString();\n            } else if (symbol.type) {\n                return '%' + symbol.type;\n            } else if (symbol.test) {\n                return '<' + String(symbol.test) + '>';\n            } else {\n                throw new Error('Unknown symbol type: ' + symbol);\n            }\n        }\n    }\n\n    return {\n        Parser: Parser,\n        Grammar: Grammar,\n        Rule: Rule,\n    };\n\n}));\n\n\n//# sourceURL=webpack://js-porth/./node_modules/nearley/lib/nearley.js?");

/***/ }),

/***/ "./src/index.ts":
/*!**********************!*\
  !*** ./src/index.ts ***!
  \**********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.main = exports.captureEval = void 0;\nconst nearley_1 = __importDefault(__webpack_require__(/*! nearley */ \"./node_modules/nearley/lib/nearley.js\"));\nconst grammar = __webpack_require__(/*! ../grammar.js */ \"./grammar.js\");\nconst left = (a) => ({ type: \"fail\", value: a });\nconst right = (b) => ({ type: \"success\", value: b });\nfunction parse(code) {\n    const parser = new nearley_1.default.Parser(nearley_1.default.Grammar.fromCompiled(grammar));\n    try {\n        parser.feed(code);\n        if (parser.results.length > 1) {\n            for (let i = 0; i < parser.results.length; i++) {\n                console.log(\"ambiguous parser\");\n            }\n            return left(\"ambiguous parser\");\n        }\n        if (parser.results.length === 0) {\n            return left(\"no parse found\");\n        }\n        return right(parser.results[0]);\n    }\n    catch (e) {\n        return left(e);\n    }\n}\nconst getContext = async (ast) => {\n    let ctx = {\n        procs: {},\n        consts: {},\n        memories: {},\n        memorySize: 0\n    };\n    for (const node of ast) {\n        if (node.type === \"const\") {\n            ctx.consts[node.name] = evalStatements(node.body, ctx);\n        }\n        if (node.type === \"proc\") {\n            ctx.procs[node.name] = genCodeAux(node.body, ctx);\n        }\n        if (node.type === \"memory\") {\n            ctx.memories[node.name] = ctx.memorySize;\n            ctx.memorySize += evalStatements(node.body, ctx);\n        }\n    }\n    let l = ast.length;\n    for (let i = 0; i < l; i++) {\n        let node = ast[i];\n        if (node.type === \"identifier\") {\n            if (node.value in ctx.consts) {\n            }\n            else if (node.value in ctx.memories) {\n            }\n            else if (node.value in ctx.procs) {\n            }\n            else {\n                throw new Error(`no value found for the idenfitifer: ${node.value}`);\n            }\n        }\n        if (node.type === \"const\") {\n            ast.splice(i, 1);\n            l--;\n        }\n        if (node.type === \"proc\") {\n            ast.splice(i, 1);\n            l--;\n        }\n        if (node.type === \"include\") {\n            try {\n                let req = await fetch(node.file.value);\n                const text = await req.text();\n                console.log(\"text is\", text);\n                const file = await parseAndProcess(text);\n                ast.splice(i, 1);\n                ctx = {\n                    consts: Object.assign(Object.assign({}, ctx.consts), file.context.consts),\n                    procs: Object.assign(Object.assign({}, ctx.procs), file.context.procs),\n                    memories: Object.assign(Object.assign({}, ctx.memories), file.context.memories),\n                    memorySize: ctx.memorySize + file.context.memorySize,\n                };\n                ast.splice(i, 0, ...file.ast);\n                l += file.ast.length - 1;\n            }\n            catch (e) {\n                console.log(\"error is\", e);\n                throw new Error(`cannot include file (it doesn't exist)`);\n            }\n        }\n    }\n    return { ast, context: ctx };\n};\nfunction evalStatements(ast, ctx) {\n    const evalledCode = `${genCode(ast, ctx)};\\n return JSON.stringify(stack[0]);`;\n    const code = new Function(evalledCode);\n    return code();\n}\nfunction assertUnreachable(x) {\n    throw new Error(` ${JSON.stringify(x, null, 4)} Didn't expect to get here`);\n}\nfunction genCodeAux(ast, ctx) {\n    return ast.map((node) => {\n        let code = \"\";\n        switch (node.type) {\n            case \"number_literal\":\n                code += `stack.push(${node.value})`;\n                break;\n            case \"string_literal\":\n                code += `stack.push(${JSON.stringify(node.value)})`;\n                break;\n            case \"plus\":\n                code += `stack.plus()`;\n                break;\n            case \"minus\":\n                code += `stack.minus()`;\n                break;\n            case \"print\":\n                code += `stack.print()`;\n                break;\n            case \"const\":\n                code += `stack.push(${ctx.consts[node.name]})`;\n                break;\n            case \"while\":\n                code += `\n// while loop\nwhile (\n    ((stack) => { ${genCodeAux(node.condition, ctx)}; return stack.pop() })(stack)) { ${genCodeAux(node.body, ctx)} } `;\n                break;\n            case \"swap\":\n                code += `stack.swap()`;\n                break;\n            case \"over\":\n                code += `stack.over()`;\n                break;\n            case \"dup\":\n                code += `stack.dup()`;\n                break;\n            case \"mod\":\n                code += `stack.mod()`;\n                break;\n            case \"drop\":\n                code += `stack.drop()`;\n                break;\n            case \"lt\":\n                code += `stack.lt(); `;\n                break;\n            case \"gt\":\n                code += `stack.gt(); `;\n                break;\n            case \"identifier\":\n                code += `//identifier ${node.value} \\n`;\n                if (node.value in ctx.consts) {\n                    code += `stack.push(${ctx.consts[node.value]})`;\n                }\n                else if (node.value in ctx.procs) {\n                    code += `${node.value}()`;\n                }\n                else if (node.value in ctx.memories) {\n                    code += `stack.push(${ctx.memories[node.value]})`;\n                }\n                else {\n                    throw new Error(`undefined indentifier ${node.value}`);\n                }\n                break;\n            case \"eq\":\n                code += \"stack.eq()\";\n                break;\n            case \"macro\":\n                throw new Error(`should not occur at this stage of compilation`);\n            case \"memory\":\n                code += `stack.push(${ctx.memories[node.name]})`;\n                break;\n            case \"if\":\n                code += `if(stack.pop()){${genCodeAux(node.body, ctx)}}`;\n                break;\n            case \"ifElse\":\n                code += `if(stack.pop()){${genCodeAux(node.body, ctx)}}else{ ${node.elseCondition ? genCodeAux(node.elseCondition, ctx) : \"\"}; ${genCodeAux(node.elseBranch, ctx)}}`;\n                break;\n            case \"proc\":\n                throw new Error(`proc should not occur here this is a bug in parsing.`);\n            case \"comment\":\n                code += `//${node.value} \\n`;\n                break;\n            case \"load8\":\n                code += `stack.load8()`;\n                break;\n            case \"store8\":\n                code += `stack.store8()`;\n                break;\n            case \"shl\":\n                code += `stack.shr()`;\n                break;\n            case \"shr\":\n                code += `stack.shl()`;\n                break;\n            case \"or\":\n                code += `stack.or()`;\n                break;\n            case \"and\":\n                code += `stack.and()`;\n                break;\n            case \"include\":\n                code += `// include file \\n`;\n                break;\n            default:\n                return assertUnreachable(node);\n        }\n        return code;\n    }).join(\";\\n\");\n}\nfunction genCode(ast, ctx) {\n    const main = genCodeAux(ast, ctx);\n    const header = `let stack = []; \\n\n    let memory  = new Uint8Array(${ctx.memorySize});    \nArray.prototype.lt = function () {\n    let a = this.pop();\n    let b = this.pop();\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for lt\")\n    return this.push(b < a)\n}\nArray.prototype.gt = function () {\n    let a = this.pop();\n    let b = this.pop();\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for lt\")\n    return this.push(b > a)\n}\nArray.prototype.eq = function () {\n    let a = this.pop();\n    let b = this.pop();\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for eq\")\n    return this.push(a === b)\n}\nArray.prototype.mod = function () {\n    let a = this.pop()\n    let b=  this.pop()\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for mod\")\n    return this.push(b % a )\n}\nArray.prototype.shl = function () {\n    let a = this.pop()\n    let b=  this.pop()\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for shl\")\n    return this.push(b >> a )\n};\nArray.prototype.shr = function () {\n    let a = this.pop()\n    let b=  this.pop()\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for shr\")\n    return this.push(b << a )\n}\nArray.prototype.or = function () {\n    let a = this.pop()\n    let b=  this.pop()\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for or\")\n    return this.push(b || a )\n};\nArray.prototype.and = function () {\n    let a = this.pop()\n    let b=  this.pop()\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for and\")\n    return this.push(b && a )\n}\nArray.prototype.over = function () {\n    let a = this.pop()\n    let b = this.pop()\n    if (a === undefined || b === undefined) {\n        throw new Error(\"not enough arguments for over intrinsic\")\n    }\n    this.push(b)\n    this.push(a)\n    this.push(b)\n}\nArray.prototype.dup = function () {\n    let a = this.pop()\n    if(a===undefined) throw new Error(\"not enough arguments for dup\")\n    this.push(a)\n    this.push(a)\n}\nArray.prototype.drop = function () {\n    let a= this.pop()\n    if(a===undefined) throw new Error(\"not enough arguments for drop\")\n}\nArray.prototype.plus = function () {\n    let a = this.pop();\n    let b = this.pop();\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for plus\")\n    this.push(a+b)\n}\nArray.prototype.minus = function () {\n    let a = this.pop();\n    let b = this.pop();\n    if(a===undefined || b===undefined) throw new Error(\"not enough arguments for minus\")\n    this.push(a-b)\n}\nArray.prototype.print = function () {\n    let a =this.pop()\n    if(a===undefined) throw new Error(\"not enough arguments for print\")\n    console.log(a)\n}\nArray.prototype.swap = function () {\n    let a = this.pop()\n    let b = this.pop()\n    if (a === undefined || b === undefined) {\n        throw new Error(\"not enough arguments for swap intrinsic\")\n    }\n    this.push(a)\n    this.push(b)\n}\nArray.prototype.store8 = function () {\n    let a = this.pop()\n    let b = this.pop()\n    if (a === undefined || b===undefined) throw new Error(\"not enough arguments for store8 intrinsic\")\n    memory[a] = b;\n}\nArray.prototype.load8 = function () {\n    let a = this.pop()\n    if (a === undefined ) throw new Error(\"not enough arguments for load8 intrinsic\")\n    this.push(memory[a])\n}\n    `;\n    const procs = Object.entries(ctx.procs).map(([key, value]) => {\n        return `function ${key}(){\n           ${value}\n        };\\n`;\n    });\n    return header + procs + main;\n}\nasync function parseAndProcess(s) {\n    const maybeAST = parse(s);\n    if (maybeAST.type === \"fail\") {\n        throw new Error(maybeAST.value);\n    }\n    else {\n        return await getContext(maybeAST.value);\n    }\n}\nconst captureEval = (code) => {\n    try {\n        let stdout = \"\";\n        let tmp = console.log;\n        console.log = (msg) => {\n            stdout += `${msg}\\n`;\n            tmp(msg);\n        };\n        eval(code);\n        console.log = tmp;\n        return stdout;\n    }\n    catch (e) {\n        return `${e}`;\n    }\n};\nexports.captureEval = captureEval;\nasync function main(prog) {\n    console.log(\"prog is\", prog);\n    const maybeAST = parse(prog);\n    if (maybeAST.type === \"fail\") {\n        return maybeAST.value;\n    }\n    else {\n        try {\n            const { ast, context } = await getContext(maybeAST.value);\n            const code = genCode(ast, context);\n            return code;\n        }\n        catch (e) {\n            return `throw new Error(\"Compiler error: ${e}\")`;\n        }\n    }\n}\nexports.main = main;\n\n\n//# sourceURL=webpack://js-porth/./src/index.ts?");

/***/ }),

/***/ "./src/web/index.ts":
/*!**************************!*\
  !*** ./src/web/index.ts ***!
  \**************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst index_1 = __webpack_require__(/*! ../index */ \"./src/index.ts\");\nconst input = document.getElementById(\"input\");\nconst output = document.getElementById(\"output\");\nconst outputjs = document.getElementById(\"outputjs\");\nconst run = document.getElementById(\"run\");\nconst autorun = document.getElementById(\"autorun\");\nconst set = async () => {\n    console.log(\"input changed\");\n    const jscode = await (0, index_1.main)(input.value);\n    outputjs.innerText = jscode;\n    output.innerText = (0, index_1.captureEval)(jscode);\n};\nrun.onclick = () => {\n    set();\n};\ninput.onchange = () => {\n    if (autorun.checked) {\n        set();\n    }\n};\ninput.oninput = () => {\n    if (autorun.checked) {\n        set();\n    }\n};\nset();\nconsole.log(\"build loaded\");\n\n\n//# sourceURL=webpack://js-porth/./src/web/index.ts?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/web/index.ts");
/******/ 	
/******/ })()
;